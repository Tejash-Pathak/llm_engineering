{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecc18a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28c3eb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a149f656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content such as images, videos, music, and text, reducing the need for human writers and artists.\n",
      "2. **Marketing Automation**: Generative AI can be used to create personalized marketing materials, such as product descriptions, ads, and social media posts, in real-time based on customer data and behavior.\n",
      "3. **Product Design**: Generative AI can generate 3D models and product designs, streamlining the product development process and reducing design costs.\n",
      "4. **Financial Analysis**: Generative AI can analyze large datasets of financial information to identify trends, predict market movements, and create predictive models for investment decisions.\n",
      "5. **Customer Service**: Generative AI-powered chatbots can provide 24/7 customer support, answering common queries and routing complex issues to human representatives.\n",
      "6. **Creative Writing**: Generative AI can be used to generate creative writing, such as stories, poems, and scripts, for various applications like entertainment, advertising, or educational content.\n",
      "7. **Data Visualization**: Generative AI can create interactive data visualizations, enabling businesses to better understand complex data trends and patterns.\n",
      "8. **Language Translation**: Generative AI can improve language translation accuracy and speed, facilitating global communication and collaboration.\n",
      "9. **Predictive Maintenance**: Generative AI can analyze sensor data from industrial equipment to predict maintenance needs, reducing downtime and increasing efficiency.\n",
      "10. **Supply Chain Optimization**: Generative AI can optimize supply chain operations by analyzing large datasets of logistics information, predicting demand, and identifying bottlenecks.\n",
      "\n",
      "In various industries, generative AI is being applied in the following ways:\n",
      "\n",
      "* **Healthcare**: Generating medical imaging data, creating personalized treatment plans, and developing virtual patients for clinical trials.\n",
      "* **Retail**: Creating personalized product recommendations, generating product images and videos, and optimizing store layouts.\n",
      "* **Media and Entertainment**: Generating music tracks, creating movie scripts, and animating characters.\n",
      "* **Education**: Developing adaptive learning systems, generating educational content, and creating interactive simulations.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abdb57e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (0.4.4)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from ollama) (2.10.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can create high-quality, personalized content such as articles, social media posts, product descriptions, and more.\n",
      "2. **Marketing Automation**: AI-powered tools can generate dynamic ad copy, optimize email campaigns, and personalize customer experiences based on individual preferences.\n",
      "3. **Product Design**: Generative AI can help design new products, visualize 3D models, and create prototypes quickly and efficiently.\n",
      "4. **Data Analysis**: AI-powered tools can analyze large datasets, identify patterns, and generate insights that inform business decisions.\n",
      "5. **Chatbots and Virtual Assistants**: Generative AI enables the creation of conversational interfaces that can engage with customers, answer questions, and provide support.\n",
      "6. **Image and Video Generation**: AI can generate high-quality images and videos for marketing campaigns, product showcases, or training purposes.\n",
      "7. **Personalization**: Generative AI can analyze customer behavior, preferences, and demographics to create personalized recommendations, offers, and experiences.\n",
      "8. **Speech Recognition**: AI-powered tools can transcribe audio recordings, generate spoken content, and even create voice-based interfaces.\n",
      "9. **Risk Analysis**: Generative AI can help identify potential risks and opportunities by analyzing large datasets, identifying patterns, and providing predictive insights.\n",
      "10. **Cybersecurity**: AI-powered tools can detect anomalies in network traffic, identify potential security threats, and respond quickly to incidents.\n",
      "\n",
      "Industry-specific applications:\n",
      "\n",
      "1. **Finance**: Generative AI can help with risk analysis, portfolio optimization, and trading strategies.\n",
      "2. **Healthcare**: AI-powered tools can analyze medical images, generate patient reports, and personalize treatment plans.\n",
      "3. **Manufacturing**: Generative AI can optimize production processes, design new products, and predict maintenance needs.\n",
      "4. **Education**: AI-powered tools can create personalized learning experiences, grade assignments, and provide feedback to students.\n",
      "5. **E-commerce**: Generative AI can help with product description generation, customer segmentation, and recommendation engines.\n",
      "\n",
      "Benefits of generative AI in business:\n",
      "\n",
      "1. **Increased efficiency**: Automate repetitive tasks, free up resources for strategic initiatives.\n",
      "2. **Improved accuracy**: Reduce errors, inconsistencies, and biases in content creation and analysis.\n",
      "3. **Enhanced personalization**: Create tailored experiences that meet individual customer needs.\n",
      "4. **New revenue streams**: Explore new business opportunities through AI-generated content, services, or products.\n",
      "5. **Competitive advantage**: Stay ahead of competitors by leveraging AI-driven insights, innovations, and efficiency gains.\n",
      "\n",
      "However, it's essential to consider the limitations and challenges associated with generative AI, such as:\n",
      "\n",
      "1. **Data quality and availability**\n",
      "2. **Bias and fairness concerns**\n",
      "3. **Explainability and transparency**\n",
      "4. **Regulatory compliance and ethics**\n",
      "5. **Human-AI collaboration and skills development**\n",
      "\n",
      "To unlock the full potential of generative AI in business, organizations should prioritize responsible innovation, data curation, and continuous learning to ensure that these technologies align with their strategic goals and values.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "401c15fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (1.58.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (2.10.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\tejas\\anaconda3\\envs\\llms\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI-powered tools can create high-quality content, such as articles, social media posts, and product descriptions, saving time and money for businesses.\n",
      "2. **Product Design and Development**: Generative AI algorithms can design and optimize products, including CAD models, 3D printing, and virtual reality experiences.\n",
      "3. **Marketing and Advertising**: Generative AI can create personalized ad campaigns, product recommendations, and customer segmentation models, increasing marketing efficiency and effectiveness.\n",
      "4. **Customer Service and Support**: Generative AI-powered chatbots and virtual assistants can provide customer support, answering frequent questions and routing complex issues to human representatives.\n",
      "5. **Predictive Maintenance**: Generative AI algorithms can analyze sensor data from machines and predict potential failures, reducing downtime and increasing overall equipment effectiveness.\n",
      "6. **Supply Chain Optimization**: Generative AI can optimize supply chain operations, predicting demand fluctuations, identifying bottlenecks, and recommending strategies for improvement.\n",
      "7. **Financial Modeling and Analysis**: Generative AI-powered financial models can simulate scenarios, estimate revenue, and identify potential risks, helping businesses make more informed investment decisions.\n",
      "8. **Human Resources and Talent Management**: Generative AI can analyze resumes, predict job fit, and recommend recruitment campaigns, enhancing the hiring process.\n",
      "9. **Creative Writing and Storytelling**: Generative AI tools can assist in writing creative content, such as books, scripts, or articles, collaborating with human writers to produce high-quality content.\n",
      "10. **Data Visualization and Insights**: Generative AI-powered data visualization tools can create interactive dashboards, provide predictive insights, and help businesses make data-driven decisions.\n",
      "11. **Cybersecurity Threat Detection**: Generative AI algorithms can analyze network traffic, identify potential threats, and predict malware behavior, enhancing cybersecurity defenses.\n",
      "12. **Medical Imaging Analysis**: Generative AI can analyze medical images, detecting abnormalities and providing diagnoses, helping doctors make more accurate diagnoses.\n",
      "13. **Autonomous Vehicles**: Generative AI algorithms can design and simulate autonomous vehicle scenarios, improving safety, efficiency, and overall performance.\n",
      "14. **Natural Language Processing (NLP)**: Generative AI can improve language understanding, sentiment analysis, and machine translation, enabling businesses to better communicate with customers and partners.\n",
      "15. **Architecture and Building Design**: Generative AI algorithms can design and build buildings, bridges, and other infrastructure projects, reducing costs and increasing efficiency.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As these tools continue to evolve, we can expect to see even more innovative uses across industries.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "402d5686-4e76-4110-b65a-b3906c35c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffe3bc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "December 21, 2024\n",
      "Welcome, SuperDataScientists!\n",
      "November 13, 2024\n",
      "Mastering AI and LLM Engineering – Resources\n",
      "October 16, 2024\n",
      "From Software Engineer to AI Data Scientist – resources\n",
      "August 6, 2024\n",
      "Outsmart LLM Arena – a battle of diplomacy and deviousness\n",
      "Navigation\n",
      "Home\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out. Change the website and add print statements to follow along.\n",
    "\n",
    "web = Website(\"https://edwarddonner.com\")\n",
    "print(web.title)\n",
    "print(web.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a900bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"summarise the following text: {web.title}\\n{web.text} (Charecters do not include the new line chareacters \\n)\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc55fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is a personal website of Edward Donner, a co-founder and CTO of Nebula.io, an AI startup that applies AI to help people discover their potential. The site includes:\n",
      "\n",
      "* An introduction to himself as a coder, DJ, and music producer\n",
      "* Information about his work at Nebula.io, including the company's mission and products\n",
      "* Links to resources on mastering AI and LLM engineering, transitioning from software engineer to AI data scientist, and an \"Outsmart\" arena where LLMs compete in a battle of diplomacy and deviousness\n",
      "* Contact information, including email, LinkedIn, Twitter, Facebook, and a newsletter sign-up form.\n",
      "\n",
      "The tone is informal and conversational, suggesting that the website is intended for enthusiasts and professionals interested in AI and machine learning.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9498c7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
