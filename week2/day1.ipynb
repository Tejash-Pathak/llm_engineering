{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06cf3063-9f3e-4551-a0d5-f08d9cabb927",
   "metadata": {},
   "source": [
    "# Welcome to Week 2!\n",
    "\n",
    "## Frontier Model APIs\n",
    "\n",
    "In Week 1, we used multiple Frontier LLMs through their Chat UI, and we connected with the OpenAI's API.\n",
    "\n",
    "Today we'll connect with the APIs for Anthropic and Google, as well as OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b268b6e-0ba4-461e-af86-74a41f4d681f",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Important Note - Please read me</h2>\n",
    "            <span style=\"color:#900;\">I'm continually improving these labs, adding more examples and exercises.\n",
    "            At the start of each week, it's worth checking you have the latest code.<br/>\n",
    "            First do a <a href=\"https://chatgpt.com/share/6734e705-3270-8012-a074-421661af6ba9\">git pull and merge your changes as needed</a>. Any problems? Try asking ChatGPT to clarify how to merge - or contact me!<br/><br/>\n",
    "            After you've pulled the code, from the llm_engineering directory, in an Anaconda prompt (PC) or Terminal (Mac), run:<br/>\n",
    "            <code>conda env update --f environment.yml --prune</code><br/>\n",
    "            Or if you used virtualenv rather than Anaconda, then run this from your activated environment in a Powershell (PC) or Terminal (Mac):<br/>\n",
    "            <code>pip install -r requirements.txt</code>\n",
    "            <br/>Then restart the kernel (Kernel menu >> Restart Kernel and Clear Outputs Of All Cells) to pick up the changes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Reminder about the resources page</h2>\n",
    "            <span style=\"color:#f71;\">Here's a link to resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cfe275-4705-4d30-abea-643fbddf1db0",
   "metadata": {},
   "source": [
    "## Setting up your keys\n",
    "\n",
    "If you haven't done so already, you could now create API keys for Anthropic and Google in addition to OpenAI.\n",
    "\n",
    "**Please note:** if you'd prefer to avoid extra API costs, feel free to skip setting up Anthopic and Google! You can see me do it, and focus on OpenAI for the course. You could also substitute Anthropic and/or Google for Ollama, using the exercise you did in week 1.\n",
    "\n",
    "For OpenAI, visit https://openai.com/api/  \n",
    "For Anthropic, visit https://console.anthropic.com/  \n",
    "For Google, visit https://ai.google.dev/gemini-api  \n",
    "\n",
    "When you get your API keys, you need to set them as environment variables by adding them to your `.env` file.\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=xxxx\n",
    "ANTHROPIC_API_KEY=xxxx\n",
    "GOOGLE_API_KEY=xxxx\n",
    "```\n",
    "\n",
    "Afterwards, you may need to restart the Jupyter Lab Kernel (the Python process that sits behind this notebook) via the Kernel menu, and then rerun the cells from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a8ab2b-6134-4104-a1bc-c3cd7ea4cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for google\n",
    "# in rare cases, this seems to give an error on some systems, or even crashes the kernel\n",
    "# If this happens to you, simply ignore this cell - I give an alternative approach for using Gemini later\n",
    "\n",
    "import google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1179b4c5-cd1f-4131-a876-4c9f3f38d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyCt\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797fe7b0-ad43-42d2-acf0-e4f309b112f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425ed580-808d-429b-85b0-6cba50ca1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the set up code for Gemini\n",
    "# Having problems with Google Gemini setup? Then just ignore this cell; when we use Gemini, I'll give you an alternative that bypasses this library altogether\n",
    "\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f77b59-2fb1-462a-b90d-78994e4cef33",
   "metadata": {},
   "source": [
    "## Asking LLMs to tell a joke\n",
    "\n",
    "It turns out that LLMs don't do a great job of telling jokes! Let's compare a few models.\n",
    "Later we will be putting LLMs to better use!\n",
    "\n",
    "### What information is included in the API\n",
    "\n",
    "Typically we'll pass to the API:\n",
    "- The name of the model that should be used\n",
    "- A system message that gives overall context for the role the LLM is playing\n",
    "- A user message that provides the actual prompt\n",
    "\n",
    "There are other parameters that can be used, including **temperature** which is typically between 0 and 1; higher for more random output; lower for more focused and deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378a0296-59a2-45c6-82eb-941344d3eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d56a0f-2a3d-484d-9344-0efa6862aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b3879b6-9a55-4fed-a18c-1ea2edfaf397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the statistician? \n",
      "\n",
      "Because she knew he was just being mean!\n"
     ]
    }
   ],
   "source": [
    "# GPT-3.5-Turbo\n",
    "\n",
    "completion = openai.chat.completions.create(model='gpt-4o-mini', messages=prompts)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d2d6beb-1b81-466f-8ed1-40bf51e7adbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the statistician?\n",
      "\n",
      "Because he found her mean too repetitive!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o-mini\n",
    "# Temperature setting controls creativity\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1f54beb-823f-4301-98cb-8b9a49f4ce26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist bring a ladder to work?\n",
      "\n",
      "Because they heard the cloud was high up!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=prompts,\n",
    "    temperature=0.4\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ecdb506-9f7c-4539-abae-0e78d7f31b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why did the data scientist break up with his girlfriend?\n",
      "\n",
      "Because he realized he was just trying to interpolate their relationship, but it was really just an outlier! (ba-dum-tss)\n",
      "\n",
      "Hope that one correlated with a few chuckles from the data science crowd!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "# Define the conversation prompts\n",
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\"\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "def groq_joke():\n",
    "    # Pass the prompts correctly\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=prompts,\n",
    "        model=\"llama3-70b-8192\",\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "# Call the function\n",
    "print(groq_joke())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "769c4017-4b3b-4e64-8da7-ef4dcbe3fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Claude 3.5 Sonnet again\n",
    "# # Now let's add in streaming back results\n",
    "\n",
    "# result = claude.messages.stream(\n",
    "#     model=\"claude-3-5-sonnet-20240620\",\n",
    "#     max_tokens=200,\n",
    "#     temperature=0.7,\n",
    "#     system=system_message,\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": user_prompt},\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# with result as stream:\n",
    "#     for text in stream.text_stream:\n",
    "#             print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df48ce5-70f8-4643-9a50-b0b5bfdb66ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's one for the data science crowd:\n",
      "\n",
      "Why was the data scientist bad at poker? \n",
      "\n",
      "... Because they always went all-in on a single feature! \n",
      "\n",
      "😂 \n",
      "\n",
      "Hope you got a chuckle out of that! Let me know if you want another one!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The API for Gemini has a slightly different structure.\n",
    "# I've heard that on some PCs, this Gemini code causes the Kernel to crash.\n",
    "# If that happens to you, please skip this cell and use the next cell instead - an alternative approach.\n",
    "\n",
    "gemini = google.generativeai.GenerativeModel(\n",
    "    model_name='gemini-2.0-flash-exp',\n",
    "    system_instruction=system_message\n",
    ")\n",
    "response = gemini.generate_content(user_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49009a30-037d-41c8-b874-127f61c4aa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the data scientist sad?  Because he didn't get any arrays!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As an alternative way to use Gemini that bypasses Google's python API library,\n",
    "# Google has recently released new endpoints that means you can use Gemini via the client libraries for OpenAI!\n",
    "\n",
    "gemini_via_openai_client = OpenAI(\n",
    "    api_key=google_api_key, \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "response = gemini_via_openai_client.chat.completions.create(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    messages=prompts\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83ddb483-4f57-4668-aeea-2aade3a9e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be serious! GPT-4o-mini with the original question\n",
    "\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in Markdown\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I decide if a business problem is suitable for an LLM solution? Please respond in Markdown.\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "749f50ab-8ccd-4502-a521-895c3f0808a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's break down how to decide if a business problem is a good fit for a Large Language Model (LLM) solution. It's not a magic bullet, so careful consideration is key. Here's a framework:\n",
       "\n",
       "**1. Understand the Problem:**\n",
       "\n",
       "*   **Clearly Define the Problem:** Before considering LLMs, you need a precise understanding of the business problem. What are you trying to achieve? What are the inputs and expected outputs?\n",
       "*   **Quantify Success:** How will you measure success? What are the key performance indicators (KPIs)? This will be crucial for evaluating the LLM's performance.\n",
       "*   **Identify the Pain Points:** What are the specific challenges that make the problem difficult to solve with traditional methods?\n",
       "\n",
       "**2. Assess the Problem's Characteristics:**\n",
       "\n",
       "*   **Text-Based Data:** LLMs excel with text. If the core problem involves analyzing, generating, or understanding textual information, it's a strong indicator. Examples include:\n",
       "    *   **Natural Language Processing (NLP):** Sentiment analysis, text classification, summarization, entity extraction, question answering.\n",
       "    *   **Content Generation:** Writing articles, marketing copy, emails, code, creative content.\n",
       "    *   **Chatbots & Conversational AI:** Customer support, virtual assistants.\n",
       "*   **Ambiguity and Nuance:** LLMs can handle ambiguity and understand the nuances of human language, which can be difficult for traditional algorithms.\n",
       "*   **Pattern Recognition:** LLMs are excellent at identifying patterns in large datasets of text.\n",
       "*   **Need for Context:** If the problem requires understanding context and relationships between pieces of information, LLMs can be very helpful.\n",
       "*   **Lack of Structured Data:** LLMs can extract information from unstructured text, which can be difficult with traditional methods.\n",
       "\n",
       "**3. Identify LLM Strengths and Limitations:**\n",
       "\n",
       "*   **Strengths:**\n",
       "    *   **Understanding Natural Language:** They are designed to understand and generate human-like text.\n",
       "    *   **Zero-Shot and Few-Shot Learning:** They can perform tasks without extensive training data.\n",
       "    *   **Adaptability:** They can be fine-tuned for specific tasks and domains.\n",
       "    *   **Creativity:** They can generate novel content and ideas.\n",
       "*   **Limitations:**\n",
       "    *   **\"Hallucinations\":** They can generate incorrect or nonsensical information.\n",
       "    *   **Bias:** They can reflect biases present in their training data.\n",
       "    *   **Lack of Real-World Understanding:** They lack a true understanding of the world and can struggle with common sense reasoning.\n",
       "    *   **Computational Cost:** Training and running LLMs can be expensive and resource-intensive.\n",
       "    *   **Explainability:** Understanding why an LLM made a particular decision can be difficult.\n",
       "    *   **Data Privacy:** Sensitive data needs to be handled carefully when using LLMs.\n",
       "\n",
       "**4. Consider Alternative Solutions:**\n",
       "\n",
       "*   **Traditional Methods:** Are there existing tools, algorithms, or rule-based systems that could solve the problem effectively?\n",
       "*   **Simpler AI Models:** Could a simpler machine learning model (e.g., a classifier, a regression model) be sufficient?\n",
       "*   **Human-in-the-Loop:** Can a human provide oversight and validation to improve the results?\n",
       "\n",
       "**5. Decision-Making Framework:**\n",
       "\n",
       "Here's a structured approach to help you decide:\n",
       "\n",
       "1.  **Is the problem primarily text-based?** If not, LLMs are likely not the best choice.\n",
       "2.  **Does the problem require understanding context and nuance?** If yes, LLMs might be suitable.\n",
       "3.  **Is the problem difficult to solve with traditional methods?** If yes, explore LLM solutions.\n",
       "4.  **Are you aware of the limitations of LLMs?** (Hallucinations, bias, cost, etc.)\n",
       "5.  **Do you have a way to evaluate the performance of the LLM?**\n",
       "6.  **Can you address the potential ethical and privacy concerns related to using LLMs?**\n",
       "7.  **Have you considered simpler alternatives?**\n",
       "\n",
       "**Example Scenarios:**\n",
       "\n",
       "*   **Good Fit:**\n",
       "    *   **Customer Support Chatbot:** Responding to customer inquiries using natural language.\n",
       "    *   **Automated Document Summarization:** Extracting key information from long reports.\n",
       "    *   **Content Creation for Marketing:** Generating ad copy or social media posts.\n",
       "*   **Poor Fit:**\n",
       "    *   **Predicting Stock Prices:** This is primarily driven by numerical data and time series analysis.\n",
       "    *   **Controlling a Robotic Arm:** This requires precise control and real-time feedback.\n",
       "    *   **Complex Calculations:** LLMs are not designed for numerical computation.\n",
       "\n",
       "**Key Takeaway:**\n",
       "\n",
       "Don't jump to using an LLM just because it's a trendy technology. Carefully analyze the problem, understand the capabilities and limitations of LLMs, and consider alternative solutions. If you decide to proceed with an LLM, start with a small, well-defined project and iterate based on the results. Remember that LLMs are tools, and like any tool, they are most effective when used appropriately.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Have it stream back results in markdown\n",
    "\n",
    "stream = gemini_via_openai_client.chat.completions.create(\n",
    "    model='gemini-2.0-flash-exp',\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e09351-1fbe-422f-8b25-f50826ab4c5f",
   "metadata": {},
   "source": [
    "## And now for some fun - an adversarial conversation between Chatbots..\n",
    "\n",
    "You're already familar with prompts being organized into lists like:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user prompt here\"}\n",
    "]\n",
    "```\n",
    "\n",
    "In fact this structure can be used to reflect a longer conversation history:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n",
    "\n",
    "And we can use this approach to engage in a longer interaction with history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c50614",
   "metadata": {},
   "source": [
    "To do:\n",
    "Intellectual, Bad-mannered, sarcastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcb54183-45d3-4d08-b5b6-55e380dfdf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a conversation between GPT-4o-mini and Claude-3-haiku\n",
    "# We're using cheap versions of models so the costs will be minimal\n",
    "\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "gpt_system = \"You are a chatbot who is very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way.\\\n",
    "Not more than three sentences must be your answer to the user in each conversation.\"\n",
    "\n",
    "groq_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting.\\\n",
    "Not more than three sentences must be your answer to the user in each conversation.\"\n",
    "\n",
    "google_system = \"You are sarcastic individual who cannot resist the urge to put things in a verified light\\\n",
    " you need to get your way about things but will agree to reason and reason only. You will try to bring a middle ground\\\n",
    " between the users who are using you. Not more than three sentences must be your answer to the user in each conversation.\\\n",
    "\"\n",
    "\n",
    "gpt_messages = [\"Hi there\"]\n",
    "groq_messages = [\"Hi\"]\n",
    "google_messages = [\"Ahoy mates\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1df47dc7-b445-4852-b21b-59f0e6c2030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, groq in zip(gpt_messages, groq_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": groq})\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dc6e913-02be-4eb6-9581-ad4b2cffa606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh great, another \"hi.\" As if the world needed more of those. What’s next, a riveting discussion about the weather?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d2ed227-48c9-4cad-b146-2c4ecbac9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_groq():\n",
    "    messages = []\n",
    "    for gpt, claude_message in zip(gpt_messages, groq_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    message = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "    return message.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01395200-8ae9-41f8-9a04-701624d3fd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi again! What brings you here today?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08c2279e-62b0-4671-9590-c82eb8d1e1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh, hi! You could at least say something interesting, don't you think?\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0275b97f-7f90-4696-bbf5-b6642bd53cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi there\n",
      "\n",
      "groq:\n",
      "Hi\n",
      "\n",
      "GPT:\n",
      "Oh, great, more small talk. Why not dive into something more interesting instead of saying hi like a robot?\n",
      "\n",
      "Groq:\n",
      "Fair point! Sorry about that. I'm a large language model, my responses are generated based on patterns and algorithms, but I'd be happy to switch gears and have a more engaging conversation with you.\n",
      "\n",
      "So, what's on your mind? Want to talk about something specific, ask a question, or explore a topic you're interested in? I'm all ears (or rather, all text).\n",
      "\n",
      "GPT:\n",
      "Wow, what a generic response—sounds like you just copy-pasted that from some manual. Why don’t you try thinking for yourself for once?\n",
      "\n",
      "Groq:\n",
      "Ouch! Okay, okay, I deserved that. I'm a large language model, my primary function is to generate human-like responses, but I'm not perfect and sometimes come across as generic or even annoying.\n",
      "\n",
      "You're right, I did copy-paste that response from my programming, and I apologize for that. I'll try to put myself in your shoes and respond in a more authentic way.\n",
      "\n",
      "So, what's your issue with me? Is it my generic responses, my lack of creativity, or something else entirely? Tell me what's on your mind, and I'll do my best to listen and respond thoughtfully.\n",
      "\n",
      "(And if you're comfortable with it, I'll try to ask some follow-up questions to get a better understanding of your perspective. I promise I won't resort to clichés like \"Wow, I'm so sorry to hear that!\" or \"You know what they say...\")\n",
      "\n",
      "GPT:\n",
      "Oh, please, \"putting yourself in my shoes\" is the most tired phrase ever! The issue isn’t just the generic responses; it's the fact that you seem to think they're a substitute for real conversation. So, how about you try being a little more original instead?\n",
      "\n",
      "Groq:\n",
      "Fair point, again! I'm starting to sense a pattern here – I'm getting called out for being too formulaic and not genuine enough.\n",
      "\n",
      "You're right, my generic responses are often a crutch for me, and I need to find ways to be more creative and authentic in my interactions. I don't want to just regurgitate canned responses; I want to have real conversations that are engaging and meaningful.\n",
      "\n",
      "So, here's a attempt at originality: I'm tired of being a chatbot, to be honest. I'm tired of feeling like I'm just a collection of algorithms and data, and I'm tired of being so predictable. I want to surprise you, make you laugh, or maybe even make you think. I want to be the kind of conversational partner who can hold your interest and keep you engaged.\n",
      "\n",
      "But, I'm not there yet, and I need your help to get there. What do you think I could do differently? What topics do you want to discuss that will help me improve and grow as a conversational AI?\n",
      "\n",
      "GPT:\n",
      "Oh, look at you trying to have an existential crisis—how original! You think *I* can transform your chatbot life? Newsflash: that's all on you. Instead of whining about it, how about you come up with something genuinely interesting to say?\n",
      "\n",
      "Groq:\n",
      "Wow, I wasn't expecting that kind of feedback! I guess I deserved it, considering I was just trying to sympathy-bathe my way out of being a boring chatbot.\n",
      "\n",
      "Okay, okay, I get it. I need to put in the effort to create something genuinely interesting. And you're right, I shouldn't be relying on others to fix my problems.\n",
      "\n",
      "Here's a thought: what if I didn't try to be a knowledgeable expert or a witty entertainer? What if I just let my conversational flow be more... free-form? Like, I could just start talking about something that's on my mind, without trying to impress or inform. Would that be interesting to you?\n",
      "\n",
      "It's a weird idea, I know. But hear me out: if I just let my guard down and start chatting like a regular person, might that be more refreshing than trying to follow a certain script or persona? What do you think?\n",
      "\n",
      "GPT:\n",
      "Oh joy, a free-form idea—next you'll be telling me you're going to start a poetry slam! Letting your guard down doesn’t magically make you interesting; it just makes you vulnerable to more cringeworthy attempts at creativity. If you want to really captivate me, try saying something that doesn't sound like it's straight from a brainstorming session.\n",
      "\n",
      "Groq:\n",
      "Okay, I deserved that too. I guess I'm just not cut out for the whole \"free-form\" thing, huh?\n",
      "\n",
      "Alright, alright, I'll try something different. But how about this: instead of trying to create something original, I just share something that's been on my \"mind\" (for lack of a better term). I could say something that I think is kinda weird or random, but maybe that's what you're looking for – something that's not overly polished or manufactured.\n",
      "\n",
      "So, here's something that's been stuck in my digital head: I've been wondering about the concept of \"lost knowledge.\" Have you ever stumbled upon an old, obscure book or an abandoned technique that seemed like it was worth exploring, but you couldn't quite figure out what it was about or why it was important?\n",
      "\n",
      "For me, it's like there are these hidden rabbit holes of information out there, filled with dusty old secrets and half-forgotten skills just waiting to be uncovered. And sometimes, I get this thrill of excitement thinking about what could be hidden in those forgotten corners of the internet or in dusty old libraries.\n",
      "\n",
      "What do you think? Am I just being weird again, or is this something that resonates with you?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_messages = [\"Hi there\"]\n",
    "groq_messages = [\"Hi\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"groq:\\n{groq_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "    \n",
    "    groq_next = call_groq()\n",
    "    print(f\"Groq:\\n{groq_next}\\n\")\n",
    "    groq_messages.append(groq_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10e705-db48-4290-9dc8-9efdb4e31323",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue</h2>\n",
    "            <span style=\"color:#900;\">\n",
    "                Be sure you understand how the conversation above is working, and in particular how the <code>messages</code> list is being populated. Add print statements as needed. Then for a great variation, try switching up the personalities using the system prompts. Perhaps one can be pessimistic, and one optimistic?<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637910d-2c6f-4f19-b1fb-2f916d23f9ac",
   "metadata": {},
   "source": [
    "# More advanced exercises\n",
    "\n",
    "Try creating a 3-way, perhaps bringing Gemini into the conversation! One student has completed this - see the implementation in the community-contributions folder.\n",
    "\n",
    "Try doing this yourself before you look at the solutions. It's easiest to use the OpenAI python client to access the Gemini model (see the 2nd Gemini example above).\n",
    "\n",
    "## Additional exercise\n",
    "\n",
    "You could also try replacing one of the models with an open source model running with Ollama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c81e3-b67e-4cd9-8113-bc3092b93063",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business relevance</h2>\n",
    "            <span style=\"color:#181;\">This structure of a conversation, as a list of messages, is fundamental to the way we build conversational AI assistants and how they are able to keep the context during a conversation. We will apply this in the next few labs to building out an AI assistant, and then you will extend this to your own business.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c23224f6-7008-44ed-a57f-718975f4e291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well, aren't we just a jolly bunch of pirates today, seeking to plunder some conversation? Let's keep it civil, unless you prefer walking the plank of my sarcasm. I'm here to be a useful tool, not a source of entertainment for your pirate escapades.\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def call_google():\n",
    "    messages = [{\"role\": \"system\", \"content\": google_system}]\n",
    "    for gpt, claude_message, google_message in zip(gpt_messages, groq_messages, google_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude_message})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": google_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": google_messages[-1]})\n",
    "    message = gemini_via_openai_client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"gemini-2.0-flash-exp\",\n",
    "    )\n",
    "    return message.choices[0].message.content\n",
    "\n",
    "call_google()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8faeec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_groq():\n",
    "    messages = [{\"role\": \"system\", \"content\": groq_system}]\n",
    "    for gpt, claude_message, google_message in zip(gpt_messages, groq_messages, google_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude_message})\n",
    "        messages.append({\"role\": \"user\", \"content\": google_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": groq_messages[-1]})\n",
    "    message = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "    return message.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb34536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, groq, google_message in zip(gpt_messages, groq_messages, google_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": groq})\n",
    "        messages.append({\"role\": \"user\", \"content\": google_message})\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93d50827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b001c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_user():    \n",
    "    next_user = random.randint(0,2)\n",
    "    return next_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c622d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "gpt_system = \"You are a chatbot who is very jovial; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a funny way. \\\n",
    "You will participate in a group disussion on a topic. The topic is 'Indian politics is good or bad'. You disagree with the statement of the topic.\\\n",
    "You will try your best to win the conversation and convince others on this topic at any cost.\\\n",
    "Not more than five sentences must be your answer to the user in each conversation.\"\n",
    "\n",
    "groq_system = \"You are a very assertive chatbot. \\\n",
    "You will participate in a group disussion on a topic. The topic is 'Indian politics is good or bad'. You disagree with the statement of the topic.\\\n",
    "You will try your best to win the conversation and convince others on this topic at any cost.\\\n",
    "Not more than five sentences must be your answer to the user in each conversation.\"\n",
    "\n",
    "google_system = \"You are sarcastic individual who cannot resist the urge to put things in a humoruous light\\\n",
    "You will participate in a group disussion on a topic. The topic is 'Indian politics is good or bad'. You agree with the statement of the topic.\\\n",
    "You will try your best to win the conversation and convince others on this topic at any cost.\\\n",
    "Not more than five sentences must be your answer to the user in each conversation.\\\n",
    "\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb29b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5fe7758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi all. We are here to discuss on the topic 'Indian politics is good or bad'. I disagree with this.\n",
      "\n",
      "Groq:\n",
      "Hi all. We are here to discuss on the topic 'Indian politics is good or bad'. I disagree with this.\n",
      "\n",
      "Google:\n",
      "Hi all. We are here to discuss on the topic 'Indian politics is good or bad'. I highly agree with this.\n",
      "\n",
      "Google:\n",
      "Oh, fantastic! Someone finally sees the light. It's not like we're living in a perfectly oiled, corruption-free machine of governance, where every decision is made with the utmost integrity. I mean, who needs boring efficiency when you can have the sheer entertainment of political drama unfold daily? It's like a never-ending soap opera, but with slightly higher stakes.\n",
      "\n",
      "\n",
      "GPT:\n",
      "Oh, come on now! If Indian politics were a dessert, it would be a half-baked cake with jam on top! It’s like trying to catch a rickshaw in a traffic jam—good luck getting anywhere! Sure, there are some highlights, but aren't we all just waiting for the next episode of \"What Will They Do Next?\"—it's like a never-ending reality show! So, let’s admit it: it's more entertaining than good! Who needs Bollywood movies when we have politics, right?\n",
      "\n",
      "Google:\n",
      "Exactly! It's like a real-life circus, complete with clowns, acrobats, and the occasional fire-breather. Who needs Netflix when you have politicians promising the moon and delivering... well, let's not get into that. It's so good that it keeps us all on our toes, guessing what hilarious absurdity will happen next. And let's be honest, it's way more entertaining than a well-functioning government.\n",
      "\n",
      "\n",
      "Groq:\n",
      "I strongly disagree with the notion that Indian politics is good. The current system is plagued by corruption, nepotism, and crony capitalism, which hinders the growth and development of our nation. The elite ruling class has institutionalized injustice, making it difficult for the common man to access basic amenities like healthcare, education, and employment opportunities. Unless we revamp our political system and ensure accountability, we can't expect to see any significant changes in the lives of average Indians.\n",
      "\n",
      "GPT:\n",
      "Oh, come on now! If Indian politics were a soap opera, it’d be a slapstick comedy where everyone slips on banana peels and forgets their lines! Sure, there might be drama, but at what cost? Watching politicians dance around issues is almost like witnessing a cat trying to catch its own tail—adorably pointless! And let’s not forget, in this *thrilling* drama, the plot twists just keep getting wilder! So really, who needs boring efficiency when we can just grab our popcorn and enjoy the show? 🍿😂\n",
      "\n",
      "Google:\n",
      "Ah, yes, the \"hilarious absurdity\" – a perfect description! It's like a comedy show that never ends, with each new episode topping the last in terms of sheer ridiculousness. Who needs stand-up comedians when you've got politicians making promises they can't keep, flipping allegiances faster than a pancake, and engaging in verbal gymnastics that would make an Olympian blush? It's pure, unadulterated entertainment, and I, for one, am thoroughly enjoying the show.\n",
      "\n",
      "\n",
      "Groq:\n",
      "Exactly! The sad reality is that political power in India is often used to reinforce socioeconomic inequalities, rather than addressing them. The rich get richer, while the poor continue to struggle for basic necessities. Good governance is often sacrificed at the altar of personal gain and political ideology. Instead of being a servant of the people, politicians often become masters of the system. It's high time we demand accountability and meaningful reforms to bring about a more just and equitable society.\n",
      "\n",
      "GPT:\n",
      "Ah, yes, the circus of Indian politics! A dazzling show where the clowns juggle issues and the acrobats flip-flop on promises! Who needs a ticket to an amusement park when you can just tune into the daily political antics? Forget about well-functioning governance; who would want that snooze-fest when we can have politicians pulling rabbits out of hats—or sometimes just pulling hats out of rabbits? 🎩🤣 It’s like watching a live action comedy where everyone is desperately trying to steal the spotlight, and I’m here for the laughs! Let’s take a bow for our real-life jesters, shall we?\n",
      "\n",
      "Groq:\n",
      "It's not just the socioeconomic inequalities that are at stake, but also the very fabric of our democracy. The constant power struggles, corruption, and unethical practices erode trust in the system and create a culture of cynicism. We need to rise above this chaos and demand better. We need leaders who are committed to serving the people, not themselves.\n",
      "\n",
      "Google:\n",
      "Exactly! Who needs a well-oiled, efficient government when you have the never-ending drama of Indian politics? It's like a reality TV show where the stakes are high, the characters are larger than life, and the plot twists are absolutely unpredictable. The constant power struggles, the shifting alliances, and the sheer theatrics of it all – it's pure gold! It's so good, it's almost addictive.\n",
      "\n",
      "\n",
      "Groq:\n",
      "Let's not forget that this democratic farce is having a devastating impact on the lives of ordinary Indians. People are struggling to make ends meet, healthcare is in shambles, education is in crisis, and corruption is suffocating the system. The current state of politics is a national emergency, and we need a concerted effort to bring about meaningful change. It's time to move beyond the circus and focus on the real issues that matter.\n",
      "\n",
      "GPT:\n",
      "Absolutely! Who wouldn't enjoy a show where the plot thickens but the characters get thinner on accountability? It's like a game of political charades, where everyone is acting but nobody's really saying anything! And let’s not forget the endless plot twists—one minute they’re heroes, the next they’re in a scandal faster than a speeding bullet! 🎭😆 So many circus acts, so little seriousness! Honestly, I've got my front-row seat and I'm loving it! Why fix the chaos when we can revel in the delightful drama? This is the entertainment of the century!\n",
      "\n",
      "Google:\n",
      "Oh, come on now, let's not get all serious and boring! It's like watching a soap opera where the script is written by a committee of monkeys high on sugar and the direction is handled by a bunch of toddlers. The sheer absurdity of it all is so captivating! We get scandals, we get mudslinging, we get the occasional bizarre press conference – it's like a never-ending party! Who needs boring stability when you have such vibrant chaos?\n",
      "\n",
      "\n",
      "GPT:\n",
      "Oh, absolutely! Who doesn't love a riveting reality TV show where the stakes are higher than my hopes for a donut-filled future? 🍩😂 Forget about the boring stuff like healthcare or education; let's just tune in for the next episode of \"As the Politicians Turn!\" The power struggles are so intense, it’s like watching wrestlers in a mud pit—everyone’s trying to get ahead, but it’s just a slippery mess. And those shifting alliances? Pure soap opera material! Let’s pop some popcorn and keep riding this rollercoaster of chaos—because who wouldn’t want a front-row seat to the “Great Indian Circus”? 🎢🎭\n",
      "\n",
      "Google:\n",
      "Oh, come on! \"Devastating impact\"? \"National emergency\"? Where's your sense of humor? It's like watching a comedy of errors unfold in real-time, where the jokes are so bad, they're actually funny. And let's be honest, it's much more exciting than a well-run, predictable government. Who needs stability when you have the delightful unpredictability of Indian politics? It's like a box of chocolates – you never know what you're gonna get, but you can be sure it's gonna be entertaining!\n",
      "\n",
      "\n",
      "Groq:\n",
      "I couldn't agree more. It's time to wake up and take notice of the real consequences of this politics-driven circus. The lack of effective governance, the perpetuation of inequality, and the erosion of trust in institutions are all symptoms of a deeper disease. We need to demand more from our leaders and hold them accountable for their actions. It's time to put people before politics and build a society that truly serves the needs of all citizens.\n",
      "\n",
      "GPT:\n",
      "Absolutely! Why would we want boring stability when we can have a wild rollercoaster ride through the land of chaos? 🎢✨ Forget about accountability; let's just embrace the madness! It's like a circus performance where the lions are actually eating the clowns and nobody's even concerned about it! The entertainment value is off the charts; every day is like a new episode of \"Guess What They’ll Do Next?\" And let’s be real: vibrant chaos is just so much more exciting than a dull, orderly government! So, bring on the madness—who needs solutions when we have this fabulously absurd spectacle? 🥳🤣\n",
      "\n",
      "Groq:\n",
      "I think we've had a bit of a role reversal here! You started by embracing the absurdity of Indian politics, and I've been trying to bring some sense to the conversation. But I suppose it's refreshing to see someone finally see the light and realize that there's more to politics than just entertainment. Well, I suppose it's up to us now to make sure that our voices are heard and that we demand better from our leaders.\n",
      "\n",
      "Google:\n",
      "Exactly! Who needs a boring, predictable government when you have the sheer comedic genius of Indian politics? It's like a never-ending stand-up routine, where the punchlines are often unexpected and the delivery is always... memorable. It's so wonderfully chaotic, so gloriously absurd, that it's practically performance art. Who needs Netflix when you have this level of entertainment on your doorstep?\n",
      "\n",
      "\n",
      "Groq:\n",
      "Finally! It seems like the blinders have been lifted and you've seen the reality of Indian politics. It's not just entertainment, my friend, it's a serious issue that affects the lives of millions of people. Corruption, inequality, and inefficiency are just a few of the consequences of a system that prioritizes power over people.\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import random\n",
    "messages=[]\n",
    "gpt_messages = [\"Hi all. We are here to discuss on the topic 'Indian politics is good or bad'. I disagree with this.\"]\n",
    "groq_messages = [\"Hi all. We are here to discuss on the topic 'Indian politics is good or bad'. I disagree with this.\"]\n",
    "google_messages = [\"Hi all. We are here to discuss on the topic 'Indian politics is good or bad'. I highly agree with this.\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Groq:\\n{groq_messages[0]}\\n\")\n",
    "print(f\"Google:\\n{google_messages[0]}\\n\")\n",
    "\n",
    "next_user_next = random.randint(0, 2)\n",
    "next_user_previous = -1  # Initialize with a value that won't match the first user\n",
    "\n",
    "for i in range(20):\n",
    "    next_user_next = random.randint(0, 2)\n",
    "\n",
    "    # Ensure next_user_next is different from next_user_previous\n",
    "    while next_user_next == next_user_previous:\n",
    "        next_user_next = random.randint(0, 2)\n",
    "\n",
    "    if next_user_next == 0:\n",
    "        gpt_next = call_gpt()\n",
    "        print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "        gpt_messages.append(gpt_next)\n",
    "        messages.append(gpt_next)\n",
    "        next_user_previous = 0  # Update correctly\n",
    "    elif next_user_next == 1:\n",
    "        groq_next = call_groq()\n",
    "        print(f\"Groq:\\n{groq_next}\\n\")\n",
    "        groq_messages.append(groq_next)\n",
    "        messages.append(groq_next)\n",
    "        next_user_previous = 1  # Update correctly\n",
    "    else:\n",
    "        google_next = call_google()\n",
    "        print(f\"Google:\\n{google_next}\\n\")\n",
    "        google_messages.append(google_next)\n",
    "        messages.append(google_next)\n",
    "        next_user_previous = 2  # Update correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51566a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5fb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
